

\section{Statement parser and evaluator}

The generic types for mathematical operations are well suited for simple expressions. However, the proposed interface can be too verbose when describing complex formulas. A more elegant solution is to represent both input and output as a literal string type and let a compiler do the parsing and evaluation of the expression. The input literal string type will contain a mathematical expression in infix notation, and the output literal string type will contain the result of the expression. The compiler is built in three parts: the lexer, the parser and the evaluator, which will be described in the following sections.

\subsection{Lexer}

The lexical analyser (lexer) is responsible for dividing the input literal string type into a sequence of meaningful units called tokens. The goal of a lexer is to remove whitespaces and inconsistencies to simplify the input stream, which is helpful for later stages of parsing. One such example is the parsing of numbers: consuming a single number token is easier than parsing each digit of a number, which can unnecessarily complicate the design of a parser.

The following section will provide an in-depth look into the handwritten lexer implementation. Namespaces have been used to describe the object types representing tokens, ensuring proper isolation between different type aliases and preventing naming clashes without the need to resort to prefixing. An example can be seen in \ref{lst:lexer-token-namespace}, where \code{Plus} and \code{Minus} are type aliases for the object types, whereas \vcode{_} is a union type for when a placeholder for a token is needed. Also, instead of utilising the \code{never} type for errors, a string enum is used to prevent unintended matches when performing assignability checks, as \code{never} is a subtype of all types.

\begin{listing}[ht]
  \begin{minted}{TypeScript}
enum Error {
  Lexer = "LexerError",
  Parser = "ParserError",
}

namespace Token {
  export type Plus = { type: "Plus" } 
  export type Minus = { type: "Minus" } 
  export type _ = Plus | Minus
} 
\end{minted}
  \caption{Lexer token namespace}\label{lst:lexer-token-namespace}
\end{listing}

The lexing itself is done by a generic type, which accepts a literal string type as a type argument and returns either a string enum as an error or an object type containing the matched token and the remaining unparsed input. As seen in Listing \code{lst:lexer-structure}, the \code{HandleToken} attempts to perform pattern matching on the first character of the input string literal type \code{T}. If succeeded, the matched token is returned wrapped in an object type defined by \code{LexResult} generic type, passing both the matched token and the remaining input to the next iteration of the \code{HandleToken} generic type. If the pattern matching fails, the \code{Error.Lexer} string enum is returned instead. This structure can be chained together to create a lexer for multiple token types, such as function keywords or numbers.

\begin{listing}[ht]
  \begin{minted}{TypeScript}
type LexResult<Rest extends string, Result extends Token._> = {
  result: Result
  rest: Rest
}
type HandleToken<T extends string> = 
  T extends `${infer Head}${infer Rest}`
  ? Head extends "+"
    ? LexResult<Rest, Token.Plus>
    : Error.Lexer
  : Head extends "-"
    ? LexResult<Rest, Token.Minus>
    : Error.Lexer
  : Error.Lexer
\end{minted}
  \caption{Lexer Structure}\label{lst:lexer-structure}
\end{listing}

\subsection{Parser}

Infix notation is the most common way of writing mathematical expressions and is more intuitive for humans to read and write. However, it is not ideal for computers due to the complexity of parsing algorithms, which must adequately evaluate parentheses and operator precedence rules. Postfix notation addresses the shortcomings of infix notation by explicitly stating the order of computation, making the evaluation unambiguous.

Various methods exist for converting an expression in infix notation. However, this thesis focuses on implementing a top-down LL(1) parser for mathematical expression. The main reason for choosing the LL(1) parser is the extendibility and suitability for supporting other LL(1) grammars more readily. Some other common parsers were considered for this thesis, including the Shunting-Yard algorithm, using two stacks for operators and output operands, and the Pratt parser, a recursive descent parsing algorithm utilising a precedence table for extendability.

In order to explain the LL(1) parser, the following sections will describe the core concepts of grammar and parsing. Grammar is a set of rules that defines the syntax of a language. The grammar $G = (\Sigma, N, R, S)$ consists of a set of terminals $\Sigma$, a set of non-terminals $N$, a set of production rules $R$ and a start symbol $S$. Terminals are the basic unit of the language, while non-terminals are placeholders for other terminals and non-terminals. Production rules define how non-terminals can be expanded into a sequence of other non-terminals and terminals, while the start symbol defines the starting non-terminal. The parsing itself will create a derivation, which is a sequence of production rules applications transforming a string of symbols, usually starting from the start symbol of the grammar.

A derivation can be visualised as a tree, also known as the derivation tree or parse tree. Each node of the tree represents a symbol in the string, and each edge represents a production rule application. The root of the tree is the start symbol of the grammar, and the leaves are the terminal symbols of the string.

There are multiple ways to construct a derivation tree: either by replacing the leftmost non-terminal symbol with the righthand side of a production rule or by replacing the rightmost non-terminal symbol with the righthand side of a production rule. The former is known as the leftmost derivation, while the latter is known as the rightmost derivation. Finally, an ambiguous grammar is a grammar that can produce multiple derivation trees for the same string.

As an example, consider the given simplified grammar for mathematical expressions applied for the expression $3 + 4 * 5$. As can be seen in Figure \ref{fig:ambiguous-grammar}, the given grammar is ambiguous, as there are multiple possible derivation trees for the given input string.

\begin{figure}[ht]
  \centering
  \begin{minipage}{0.8\linewidth}
    \begin{multicols}{2}
      \Tree [
      .E
        [ .E [ .3 ] ]
      +
      [ .E [ .E [ .4 ] ] * [ .E [ .5 ]] ]
      ]

      \Tree [
      .E
      [ .E [ .E [ .3 ] ] + [ .E [ .4 ] ] ]
      *
        [ .E [ .5 ] ]
      ]
    \end{multicols}

    \begin{multicols}{3}
      \begin{enumerate}
        \item \code{E} $\rightarrow$ \code{E} \mcode{"+"} \code{E} .
        \item \code{E} $\rightarrow$ \code{E} \mcode{"*"} \code{E} .
        \item \code{E} $\rightarrow$ \mcode{"number"} .
      \end{enumerate}
    \end{multicols}
  \end{minipage}
  \caption{An example of ambiguous grammar and the parsing tree for $3+4*5$}
  \label{fig:ambiguous-grammar}
\end{figure}



LL(1) parsers are a class of top-down parsers that read the input string from left to right and construct a leftmost derivation of the input. They use a single token of lookahead when parsing a sentence, meaning that the parser can only see the next token before parsing.  LL(1) parsers recognise LL(1) grammars, which are a special case of context-free grammars. The grammar must be unambiguous, without any left recursion and common prefixes among the alternatives of any expansion rule to be deterministic.

The parser relies upon two important concepts: the FIRST($\alpha$) and FOLLOW($A$) sets. Assuming a context-free grammar $G = (\Sigma, N, R, S)$, the FIRST($\alpha$) set is a set of terminals that can appear as the first symbol in a string derived from $\alpha$. Formally, FIRST($\alpha$) can be defined as follows:

$$\text{FIRST}(\alpha) = \{ a | \alpha \Rightarrow^\star a\beta, a \in \Sigma, \alpha, \beta \in (N \cup \Sigma)^\star \} \cup \{ \varepsilon | \alpha \Rightarrow^\star \varepsilon \}$$

The FOLLOW($A$) set is a set of terminals that can appear as the next symbol in a string derived from a given non-terminal symbol $A$. Formally, FOLLOW($A$) can be defined as follows:

$$\text{FOLLOW}(A) = \{ a | S \Rightarrow^\star \alpha A\beta, a \in \text{FIRST}(\beta) \} $$

Given both the FIRST($\alpha$) and FOLLOW($A$) sets, a parsing table can be constructed. The parsing table is created as follows: for each of the production rule $A \rightarrow \alpha$ found in the grammar, do the following:

\begin{enumerate}
  \item For each terminal $a$ found in the FIRST($\alpha$), add the production role $A \rightarrow \alpha$ to the parsing table at the position $[A, a]$.
  \item If the $\varepsilon$ token, determining the end of input, is present in the FIRST($\alpha$) set, add $A \rightarrow \alpha$ to the parsing at position $[A, b]$ for each terminal $b$ in the FOLLOW(A) set.
\end{enumerate}

When designing a LL(1) grammar for mathematical expressions, operator precedence must be taken into consideration, as the expression found in the input string literal type is written in the infix notation. Left or right associativity is a key constraint as well, with exponentiation being an operator with right associativity instead of left associativity as the other operators. The precedence and associativity rules for the operators can be seen in Table \ref{table:associativity}.

\begin{table}[ht]
  \centering
  \begin{tabular}{c|l|l}
    \hline
    \textbf{Precedence} & \textbf{Operator Type}              & \textbf{Associativity} \\ \hline
    1                   & Addition, Subtraction               & left-to-right          \\ 
    2                   & Multiplication, Division, Remainder & left-to-right          \\ 
    3                   & Factorial                           & non-associative        \\ 
    4                   & Unary plus, Unary negation          & non-associative        \\ 
    5                   & Exponentiation                      & right-to-left          \\ 
    6                   & Function call, grouping             & non-associative        \\ \hline
  \end{tabular}
  \caption{Associativity and precedence rules for math expressions}
  \label{table:associativity}
\end{table}

The final grammar used for this thesis can be seen in Figure \ref{fig:math-grammar}. The operator precedence rules are baked into the grammar itself, where the non-terminals representing the higher precedence operations are expanded later. The associativity of operators has been taken into consideration as well by changing the position of the non-terminal from the lefthand side, essentially switching from left recursion to right recursion and vice versa. An example can be seen in \ref{table:associativity-grammar}, where both the previous context-free grammar and the appropriately modified LL(1) version of the grammar is shown to demonstrate the difference between these two grammars.

\begin{figure}[ht]
  \begin{multicols}{2}
    \begin{enumerate}
      \item \code{START} $\rightarrow$ \code{ADD} .

      \item \code{ADD} $\rightarrow$ \code{MUL} \code{ADDx} .
      \item \code{ADDx} $\rightarrow$ \mcode{"+"} \code{MUL} \code{ADDx} .
      \item \code{ADDx} $\rightarrow$ \mcode{"-"} \code{MUL} \code{ADDx} .
      \item \code{ADDx} $\rightarrow$ \code{$\varepsilon$} .

      \item \code{MUL} $\rightarrow$ \code{FACT} \code{MULx} .
      \item \code{MULx} $\rightarrow$ \mcode{"*"} \code{FACT} \code{MULx} .
      \item \code{MULx} $\rightarrow$ \mcode{"/"} \code{FACT} \code{MULx} .
      \item \code{MULx} $\rightarrow$ \mcode{"%"} \code{FACT} \code{MULx} .

      \item \code{FACT} $\rightarrow$ \code{UNARY} \code{FACTx} .
      \item \code{FACTx} $\rightarrow$ \mcode{"!"} \code{FACTx} .
      \item \code{FACTx} $\rightarrow$ \code{$\varepsilon$} .

      \item \code{UNARY} $\rightarrow$ \mcode{"-"} \code{UNARY} .
      \item \code{UNARY} $\rightarrow$ \mcode{"+"} \code{UNARY} .
      \item \code{UNARY} $\rightarrow$ \code{POW} .

      \item \code{POW} $\rightarrow$ \code{TERM} \code{POWx} .
      \item \code{POWx} $\rightarrow$ \mcode{"^"} \code{POW} .
      \item \code{POWx} $\rightarrow$ \code{$\varepsilon$}.

      \item \code{TERM} $\rightarrow$ \mcode{"unary"} \mcode{"("} \code{ADD} \mcode{")"} .
      \item \code{TERM} $\rightarrow$ \mcode{"binary"} \mcode{"("} \code{ADD} \mcode{","} \code{ADD} \mcode{")"} .
      \item \code{TERM} $\rightarrow$ \mcode{"("} \code{ADD} \mcode{")"} .
      \item \code{TERM} $\rightarrow$ \mcode{"number"} .
    \end{enumerate}
  \end{multicols}
  \caption{LL(1) grammar for mathematical expressions}
  \label{fig:math-grammar}
\end{figure}


\begin{table}[h]
  \centering
  \begin{tabular}{l|l}
    \hline
    \textbf{Left associativity} & \textbf{Right associativity}                              \\
    \hline

    \makecell[l]{
    \code{ADD} $\rightarrow$ \code{TERM} \code{.}                                           \\
      \code{ADD} $\rightarrow$ \code{ADD} \mintinline{TypeScript}{"+"} \code{TERM} \code{.}
    }
                                &
    \makecell[l]{
    \code{ADD} $\rightarrow$ \code{TERM} \code{.}                                           \\
      \code{ADD} $\rightarrow$ \code{TERM} \mintinline{TypeScript}{"+"} \code{ADD} \code{.}
    }

    \\
    \hline

    \makecell[l]{
    \code{ADD} $\rightarrow$ \code{TERM} \code{ADD'} \code{.}                               \\
    \code{ADD'} $\rightarrow$ \mintinline{TypeScript}{"+"} \code{TERM} \code{ADD'} \code{.} \\
      \code{ADD'} $\rightarrow$ \code{$\varepsilon$} \code{.}
    }
                                &

    \makecell[l]{
    \code{ADD} $\rightarrow$ \code{TERM} \code{ADD'} \code{.}                               \\
    \code{ADD'} $\rightarrow$ \mintinline{TypeScript}{"+"} \code{ADD} \code{.}              \\
      \code{ADD'} $\rightarrow$ \code{$\varepsilon$} \code{.}
    }
    \\
    \hline
  \end{tabular}
  \caption{Grammar comparison between left-associativity and right-associativity}
  \label{table:associativity-grammar}
\end{table}

A custom code generation tool has been developed to generate a parser running entirely in the TypeScript type system from the provided LL(1) grammar, using the aforementioned algorithm for creating the parsing table and appropriate recursive descent parser. The interface of a parser is defined as a generic type \code{Parser}, accepting a tuple of lexer tokens and a possible output \acrshort{ast} node type as type parameters, seen in Listing \ref{lst:parser-interface}. The generic type returns an object type with an additional \code{head} property for simplifying the matching of the current lookahead token needed by the LL(1) parser. \code{ConsumeParser} is a generic type for consuming a token from the input stream and returning a new object type with the rest of the token stream.

\begin{listing}[ht]
  \begin{minted}{TypeScript}
interface Parser<T extends Token._[] = Token._[], A extends AST._ = AST._> {
  tokens: T
  head: T[0]
  return: A
}

type ConsumeParser<
    Match extends Token._,
    TParser extends Parser
  > = TParser["head"] extends Match
    ? TParser["tokens"] extends [Token._, ...infer Rest extends Token._[]]
      ? Parser<Rest, TParser["return"]>
      : []
    : Error.Parser
\end{minted}
  \caption{Core parser interface}\label{lst:parser-interface}
\end{listing}

With the following building blocks, it is possible to write a recursive descent parser based on the obtained parser table. An example can be seen in Listing \ref{lst:pow-parser}, where a non-terminal \code{POW} and \code{POWx} are transformed into generic types accepting a type instance of \code{Parser} as the type parameter. The generic type attempts to match a lexer token by performing an assignability check. If succeeded, either the token can be consumed by using \code{ConsumeParser}, yielding a new parser to work with, or the parser can be passed on to the next generic type. The \code{ReturnParser} generic type reassigns the AST node, essentially acting as a way to return a value from a generic type.

\begin{listing}[ht]
  \begin{minted}{TypeScript}
type POWx<T extends Parser> = T["head"] extends Token.Power
  ? ConsumeParser<Token.Power, T> extends infer T extends Parser
    ? POW<T> extends infer R extends Parser
      ? ReturnParser<R, AST.Binary<T["return"], "^", R["return"]>>
      : Error.Parser
    : Error.Parser
  : T["head"] extends
      | Token.EOF | Token.Factorial | Token.Multiply
      | Token.Divide | Token.Modulo | Token.Plus
      | Token.Minus | Token.RightBracket | Token.Comma
  ? T
  : Error.Parser

type POW<T extends Parser> = T["head"] extends
  | Token.UnaryFunction | Token.BinaryFunction | Token.LeftBracket | Token.Number
  ? TERM<T> extends infer T extends Parser
    ? POWx<T> extends infer T extends Parser
      ? T
      : Error.Parser
    : Error.Parser
  : Error.Parser
\end{minted}
  \caption{Implementation of exponentiation parser}\label{lst:pow-parser}
\end{listing}

\subsection{Evaluator}

Finally, the evaluator takes the \acrshort{ast} returned by the parser as the input and returns a string literal type containing the result of the expression.

As the \acrshort{ast} does already take operator precedence and associativity into account, the evaluator itself only recursively traverses the tree, visiting each of the \acrshort{ast} nodes and performing the appropriate operation by pattern matching. A shortened example can be seen in Listing \ref{lst:evaluator-example}.

\begin{listing}[ht]
  \begin{minted}{TypeScript}
export type Evaluate<T> = T extends AST.Binary<
  infer Left,
  infer Op,
  infer Right
>
  ? Op extends "+"
    ? Evaluate<Left> extends infer LeftStr extends NumberLike
      ? Evaluate<Right> extends infer RightStr extends NumberLike
        ? Add<LeftStr, RightStr>
        : never
      : never
    : never
  : T extends AST.Number<infer Value extends string>
  ? Value
  : never
\end{minted}
  \caption{Evaluator example}\label{lst:evaluator-example}
\end{listing}

The evaluator itself is not required per se, and the expression can be evaluated directly in the parser, but to avoid the instantiation depth limit and to simplify debugging and unit testing, the parser emits an \acrshort{ast} as a temporary result, and the evaluation is performed in a separate step. This does have the additional benefit of simplifying testing of the entire parsing mechanics, as the \acrshort{ast} can be easily inspected and compared to the expected result.
